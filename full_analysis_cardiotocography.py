# -*- coding: utf-8 -*-
"""Full_analysis_cardiotocography.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zCfbrccfhRrJ7kNmXWjd4q_BMjy9OQg4

**Import the libraries Needed**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns #for plotting
from sklearn.ensemble import RandomForestClassifier #for the model
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz #plot tree
from sklearn.metrics import roc_curve, auc #for model evaluation
from sklearn.metrics import classification_report #for model evaluation
from sklearn.metrics import confusion_matrix #for model evaluation
from sklearn.model_selection import train_test_split #for data splitting


np.random.seed(123) #ensure reproducibility

pd.options.mode.chained_assignment = None  #hide any pandas warnings

#Import libraries for plotting confusion metrics
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics

#Import libraries for hyperparameter tuning
from sklearn.model_selection import validation_curve
from sklearn.model_selection import learning_curve

#Import SVM
from sklearn.svm import SVC

#Import library for logistic regression
from sklearn.linear_model import LogisticRegression

#Import libraries to remove outliers
from sklearn.ensemble import IsolationForest

#Import feature selection library
!pip install pymrmr
import pymrmr

# %matplotlib inline

"""**Define the user defined functions**
Later put them in a module
"""

#Write a function to implement SVC
def custom_svc(dt,target,kernel = 'linear',cache_size=200,max_iter=-1,class_weight=None,C=1):
    X= dt.drop(target, 1)
    y = dt[target] 
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state=10) #split the data
    model = SVC(C=C, cache_size=cache_size, class_weight=class_weight, coef0=0.0,
        decision_function_shape='ovr', degree=3, gamma='auto_deprecated',
        kernel=kernel, max_iter=max_iter, probability=True, random_state=0,
        shrinking=True, tol=0.001, verbose=False)
    model.fit(X_train, y_train)
    # Use score method to get accuracy of model
    score = model.score(X_test, y_test)
    print(score)
    
    #Get the prediction results
    y_predict = model.predict(X_test)
    y_pred_quant = model.predict_proba(X_test)
    y_pred_bin = model.predict(X_test)

    #Show the confusion matrix
    #Create the confusion matrics
    cm = metrics.confusion_matrix(y_test, y_pred_bin)
    
    return score,cm,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test

#Write a function to implement logistic regression
def custom_logistic_regression(dt,target,max_iter=-1,class_weight=None,C=1.0):
    X= dt.drop(target, 1)
    y = dt[target] 
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state=10) #split the data
    model = LogisticRegression(C=C, class_weight=class_weight, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=max_iter,
                   multi_class='multinomial', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
    #Fit the model
    model.fit(X_train, y_train)
    # Use score method to get accuracy of model
    score = model.score(X_test, y_test)
    print(score)
    
    #Get the prediction results
    y_predict = model.predict(X_test)
    y_pred_quant = model.predict_proba(X_test)
    y_pred_bin = model.predict(X_test)

    #Show the confusion matrix
    #Create the confusion matrics
    cm = metrics.confusion_matrix(y_test, y_pred_bin)
    
    return score,cm,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test

#Write a function to implement random forest
def custom_random_forest(dt,target,max_depth=10, n_estimators=100,class_weight=None):
    X= dt.drop(target, 1)
    y = dt[target] 
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state=10) #split the data
    model = RandomForestClassifier(bootstrap=True, class_weight=class_weight, criterion='gini',
                       max_depth=max_depth, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=n_estimators,
                       n_jobs=None, oob_score=False, random_state=0,
                       verbose=0, warm_start=False)
    model.fit(X_train, y_train)
    # Use score method to get accuracy of model
    score = model.score(X_test, y_test)
    print(score)
    
    #Get the prediction results
    y_predict = model.predict(X_test)
    y_pred_quant = model.predict_proba(X_test)
    y_pred_bin = model.predict(X_test)

    #Show the confusion matrix
    #Create the confusion matrics
    cm = metrics.confusion_matrix(y_test, y_pred_bin)
    
    #Determine the feature importances
    # Get numerical feature importances
    importances = list(model.feature_importances_)
    
    #Extract the tree
    tree = model.estimators_[5]
    
    return score,cm,tree,importances,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test

#Define a function to determine variable importances in random forest
def rf_var_importance(importances,X_train):
    feature_list = [i for i in X_train.columns]
    # List of tuples with variable and importance
    feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]
    # Sort the feature importances by most important first
    feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)
    # Print out the feature and importances 
    [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];

#Define a function to split data
def split_data(dt,target,test_size = .20, random_state=10):
  X= dt.drop(target, 1)
  y = dt[target] 
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=random_state) #split the data
  return X_train, X_test, y_train, y_test

#Outlier Detection function
def custom_isolation_forest(dt,n_estimators=20):
  clf = IsolationForest(n_estimators=n_estimators, warm_start=True)
  clf.fit(dt)  # fit the added trees 
  outliers = clf.predict(dt) 
  dt['outliers'] = outliers
  return dt

#Outlier removal function
def outlier_removal(dt,dt_name = None):
  outlier_val_count = dt.outliers.value_counts()
  dt_no_out = dt[dt.outliers == 1]
  dt = dt.drop(['outliers'], axis = 1)
  dt_no_out = dt_no_out.drop(['outliers'], axis = 1)
  print(dt_name)
  print(outlier_val_count)
  return dt, dt_no_out

#Define a function for plotting learning curves
def plot_learning_curve(train_sizes,train_scores,test_scores, curve_name = ''):
  print('Plotting learning curve for '+curve_name)
  # Create means and standard deviations of training set scores
  train_mean = np.mean(train_scores, axis=1)
  train_std = np.std(train_scores, axis=1)

  # Create means and standard deviations of test set scores
  test_mean = np.mean(test_scores, axis=1)
  test_std = np.std(test_scores, axis=1)

  # Draw lines
  plt.plot(train_sizes, train_mean, '--', color="#111111",  label="Training score")
  plt.plot(train_sizes, test_mean, color="#111111", label="Cross-validation score")

  # Draw bands
  plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color="#DDDDDD")
  plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color="#DDDDAA")

  # Create plot
  plt.title("Learning Curve")
  plt.xlabel("Training Set Size"), plt.ylabel("Accuracy Score"), plt.legend(loc="best")
  plt.tight_layout()
  plt.show()

#Define function for plotting validation curve
def plot_validation_curve(train_scores,test_scores,param_name= ''):
  print('plotting validation curve for '+ param_name)
  # Calculate mean and standard deviation for training set scores
  train_mean = np.mean(train_scores, axis=1)
  train_std = np.std(train_scores, axis=1)

  # Calculate mean and standard deviation for test set scores
  test_mean = np.mean(test_scores, axis=1)
  test_std = np.std(test_scores, axis=1)

  # Plot mean accuracy scores for training and test sets
  plt.plot(param_range, train_mean, label="Training score", color="black")
  plt.plot(param_range, test_mean, label="Cross-validation score", color="dimgrey")

  # Plot accurancy bands for training and test sets
  plt.fill_between(param_range, train_mean - (train_std/3), train_mean + (train_std/3), color="blue")
  plt.fill_between(param_range, test_mean - (test_std/3), test_mean + (test_std/3), color="red")

  # Create plot
  plt.title("Validation Curve for "+ param_name)
  plt.xlabel(param_name)
  plt.ylabel("Accuracy Score")
  plt.tight_layout()
  plt.legend(loc="best")
  plt.show()

#Define function for plotting validation curve
def plot_validation_curve2(train_scores,test_scores,param_name= ''):
  print('plotting validation curve for '+ param_name)
  # Calculate mean and standard deviation for training set scores
  train_mean = np.mean(train_scores, axis=1)
  train_std = np.std(train_scores, axis=1)

  # Calculate mean and standard deviation for test set scores
  test_mean = np.mean(test_scores, axis=1)
  test_std = np.std(test_scores, axis=1)

  # Plot mean accuracy scores for training and test sets
  plt.plot(param_range, train_mean, label="Training score", color="black")
  plt.plot(param_range, test_mean, label="Cross-validation score", color="dimgrey")

 

  # Create plot
  plt.title("Validation Curve for "+ param_name)
  plt.xlabel(param_name)
  plt.ylabel("Accuracy Score")
  plt.tight_layout()
  plt.legend(loc="best")
  plt.show()

#Write a function to plot confusion_matrix and output the performance metrics
def plot_conf_matrix(y_test, y_pred_bin,classes = 3):
  cm = metrics.confusion_matrix(y_test, y_pred_bin)
  plt.figure(figsize=(9,9))
  sns.heatmap(cm, annot=True, fmt=".3f", linewidths=.5, square = True, cmap = 'Blues_r');
  plt.ylabel('Actual label');
  plt.xlabel('Predicted label');
  all_sample_title = 'Accuracy Score: {0}'.format(score)
  plt.title(all_sample_title, size = 15);

  # Print the precision and recall, among other metrics
  print("The precision recall, F1 score and support for each class")
  print(metrics.classification_report(y_test, y_pred_bin, digits=classes))

#Write a function for plotting multiclass ROC
def plot_roc_auc(y_test,y_pred_quant, classno = 0, class_name = 'Normal'):
  y_test_dummies = pd.get_dummies(y_test, drop_first=False).values
  fpr, tpr, thresholds = roc_curve(y_test_dummies[:,classno], y_pred_quant[:, classno])

  fig, ax = plt.subplots()
  ax.plot(fpr, tpr)
  ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls="--", c=".3")
  plt.xlim([0.0, 1.0])
  plt.ylim([0.0, 1.0])
  plt.rcParams['font.size'] = 12
  plt.title('ROC curve for class ' + class_name)
  plt.xlabel('False Positive Rate (1 - Specificity)')
  plt.ylabel('True Positive Rate (Sensitivity)')
  plt.grid(True)
  auc_val = auc(fpr, tpr)
  print("AUC for this ROC Curve is "+ str(auc_val) )

"""**Feature extraction from Cardiotocography**


*   Give reference to the paper for the dataset preparation
*   Describe how they extracted features from the Cardiotocography data

**Read the data and preprocess the data**
"""

#Read the data file , handle the categorical variables and drop garbage columns
dt = pd.read_csv('cardiotocography.csv')
dt = dt.drop(['Unnamed: 23','CLASS'],axis = 1)
dt['Tendency'][dt['Tendency'] == -1] = 'left_asymmetric'
dt['Tendency'][dt['Tendency'] == 0] = 'symmetric'
dt['Tendency'][dt['Tendency'] == 1] = 'right_asymmetric'

dt['Tendency'] = dt['Tendency'].astype('object')

dt = pd.get_dummies(dt, drop_first=False)
dt.head()

"""**outlier removal**

Outlier removal from the whole dataset
"""

#Outlier detection using isolation forest
dt = custom_isolation_forest(dt)
dt,dt_no_out = outlier_removal(dt)
NSP_count = dt.NSP.value_counts()
NSP_count_wo = dt_no_out.NSP.value_counts()
print('NSP count with outliers')
print(NSP_count_wo)
print('NSP count without outliers')
print(NSP_count)

"""Outlier removal from each class"""

##Detecting outliers from Normal class
normal = dt[dt.NSP == 1]
normal = custom_isolation_forest(normal)

##Detecting outliers from Suspected class
suspected = dt[dt.NSP == 2]
suspected = custom_isolation_forest(suspected)

##Detecting outliers from Pathological class
pathological = dt[dt.NSP == 3]
pathological = custom_isolation_forest(pathological)

#Remove outliers from each of the three class
normal, normal_no_out = outlier_removal(normal,dt_name = 'Normal')
suspected, suspected_no_out = outlier_removal(suspected,dt_name = 'Suspected')
pathological, pathological_no_out = outlier_removal(pathological,dt_name = 'Pathological')

#Merge all three classes outlier free data
outlierless_dt = pd.concat([normal_no_out,suspected_no_out,pathological_no_out],ignore_index= True)

#Random shuffle the rows of combined dataset
outlierless_dt = outlierless_dt.sample(frac = 1,random_state=1).reset_index(drop=True)
outlierless_dt.shape

"""**Feature Selection**
* Select features using MrMr algorithm
"""

nsp = outlierless_dt[['NSP']]
feature_dt = outlierless_dt.drop(['NSP'], axis = 1)

feature_dt.insert(0, 'NSP', nsp)    #For pymrmr module to select features the target column should be the first column in the dataframe
feature_dt.head()
feature_dt.shape

mrmr_features = pymrmr.mRMR(feature_dt, 'MIQ', 10)
 type(mrmr_features)
 print(mrmr_features)
 final_dt = outlierless_dt[mrmr_features]
 final_dt.insert(0, 'NSP', nsp)
 final_dt.shape
 #final_dt contains the feature selected data

"""**Feature Engineering**
1.   combine similar features
2.   Extract PCA features

**Start Analysis**

**Support Vector Machine**

Plot learning curves for linear SVM and kernel SVMS
"""

#plotting the learning curve
# Create CV training and test scores for various training set sizes
X_train, X_test, y_train, y_test = split_data(outlierless_dt,target='NSP')
train_sizes, train_scores, test_scores = learning_curve(SVC(kernel = 'linear'), 
                                                        X_train, 
                                                        y_train,
                                                        # Number of folds in cross-validation
                                                        cv=10,
                                                        # Evaluation metric
                                                        scoring='accuracy',
                                                        # Use all computer cores
                                                        n_jobs=-1, 
                                                        # 50 different sizes of the training set
                                                        train_sizes=np.linspace(0.01, 1.0, 50))

plot_learning_curve(train_sizes,train_scores,test_scores, curve_name = 'SVM linear kernel')

#plotting the learning curve for SVM with Gaussian kernel
# Create CV training and test scores for various training set sizes
X_train, X_test, y_train, y_test = split_data(outlierless_dt,target='NSP')
train_sizes, train_scores, test_scores = learning_curve(SVC(kernel = 'rbf'), 
                                                        X_train, 
                                                        y_train,
                                                        # Number of folds in cross-validation
                                                        cv=10,
                                                        # Evaluation metric
                                                        scoring='accuracy',
                                                        # Use all computer cores
                                                        n_jobs=-1, 
                                                        # 50 different sizes of the training set
                                                        train_sizes=np.linspace(0.01, 1.0, 50))

plot_learning_curve(train_sizes,train_scores,test_scores, curve_name = 'SVM Gaussian kernel')

"""Hyperparameter Tuning for SVM linear kernel

Learning the maximum iterations value **parameter 1 - max_iter**
"""

#Learn the hyperparameter maximum iterations 
X_train, X_test, y_train, y_test = split_data(outlierless_dt,target='NSP')
param_range = np.arange(0, 20000, 200 )

train_scores, test_scores = validation_curve(SVC(kernel = 'linear',cache_size=200), X_train, y_train, param_name = "max_iter",param_range = param_range
                ,scoring = 'accuracy',n_jobs=-1)
plot_validation_curve(train_scores,test_scores,param_name= 'Number of iterations')

"""Learn the hyperparameter regularization constant **parameter 2 - cost**"""

#Learn the hyperparameter regularization constant 
X_train, X_test, y_train, y_test = split_data(outlierless_dt,target='NSP')

#param_range = np.arange(1, 50, 2 )
param_range = np.logspace(start=-5, stop= 0, base= 10 )

train_scores, test_scores = validation_curve(SVC(kernel = 'linear',cache_size=200), X_train, y_train, param_name = "C",param_range = param_range
                ,scoring = 'accuracy',n_jobs=-1)
plot_validation_curve(train_scores,test_scores,param_name= 'Regularization Constant')

"""Build a SVM model without modifying the dataset(No ouutlier removal, No feature reduction) **Model 1**"""

score,cm,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test = custom_svc(dt,target = 'NSP',kernel = 'linear')
plot_conf_matrix(y_test, y_pred_bin,classes=3)

"""Draw the ROC curve and calculate the AUC"""

plot_roc_auc(y_test,y_pred_quant, classno = 0, class_name = 'Normal')

plot_roc_auc(y_test,y_pred_quant, classno = 1, class_name = 'Suspected')

plot_roc_auc(y_test,y_pred_quant, classno = 2, class_name = 'Pathologic')

"""Create a dataset with 400 normal and all the pathology and suspected datas"""

#Extract the rows with suspected and pathological NSP values
path_class  = dt[dt.NSP.isin([2,3])]
#Extraict the rows with Normal NSP value
norm_class = dt[dt.NSP == 1]
#Take first 400 data of Normal class
norm_class = norm_class.iloc[0:400,:]

#Merge normal and pathological dataset
c_dt = pd.concat([path_class,norm_class],ignore_index= True)

#Random shuffle the rows of combined dataset
c_dt = c_dt.sample(frac = 1,random_state=1).reset_index(drop=True)

#Create yet another dataset with reduced number of features
c_dt_sf = c_dt[[ 'ASTV', 'MSTV', 'ALTV', 'Mean', 'NSP']]
print(c_dt_sf.shape)
c_dt_sf.head()

"""Build SVM model for the reduced dataset **- Model 2**"""

score,cm,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test = custom_svc(c_dt,target = 'NSP',kernel = 'linear')

plot_conf_matrix(y_test, y_pred_bin,classes=3)

"""Build SVM model for data reduced and feature reduced dataset **- Model 3**"""

score,cm,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test = custom_svc(c_dt_sf,target = 'NSP',kernel = 'linear')

plot_conf_matrix(y_test, y_pred_bin,classes=3)

"""Build model with the dataset that does not have outliers(Outlier removal from the whole dataset) **- Model 4**"""

#Build model with the dataset that does not have outliers(Outlier removal from the whole dataset)
score,cm,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test = custom_svc(dt_no_out,target = 'NSP',kernel = 'linear',class_weight='balanced')

plot_conf_matrix(y_test, y_pred_bin,classes=3)

"""Build model with the dataset that does not have outliers(Outlier removal from each class of the dataset seperately) **- Model 5**"""

#Build model with the dataset that does not have outliers(Outlier removal from each class of the dataset seperately) **- Model 5**
score,cm,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test = custom_svc(outlierless_dt,target = 'NSP',kernel = 'linear',class_weight='balanced',C= 0.1)

plot_conf_matrix(y_test, y_pred_bin,classes=3)

plot_roc_auc(y_test,y_pred_quant, classno = 0, class_name = 'Normal')

plot_roc_auc(y_test,y_pred_quant, classno = 1, class_name = 'Suspected')

plot_roc_auc(y_test,y_pred_quant, classno = 2, class_name = 'Pathologic')

"""**Build SVM model with selected features Model 6**"""

#Build model with the dataset that does not have outliers(Outlier removal from each class of the dataset seperately) **- Model 5**
score,cm,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test = custom_svc(final_dt,target = 'NSP',kernel = 'linear',class_weight='balanced',C= 0.1)

plot_conf_matrix(y_test, y_pred_bin,classes=3)

plot_roc_auc(y_test,y_pred_quant, classno = 0, class_name = 'Normal')

plot_roc_auc(y_test,y_pred_quant, classno = 1, class_name = 'Suspected')

plot_roc_auc(y_test,y_pred_quant, classno = 0, class_name = 'Pathologic')

"""**Logistic regression analysis**

1.   Learning curve
2.   Max_iter tuning 
3.   build model
4.   confusion matrix and performance metrics
5.   ROC curve

1. Learning curve
"""

#plotting the learning curve
# Create CV training and test scores for various training set sizes
X_train, X_test, y_train, y_test = split_data(outlierless_dt,target='NSP')
train_sizes, train_scores, test_scores = learning_curve(LogisticRegression(), 
                                                        X_train, 
                                                        y_train,
                                                        # Number of folds in cross-validation
                                                        cv=10,
                                                        # Evaluation metric
                                                        scoring='accuracy',
                                                        # Use all computer cores
                                                        n_jobs=-1, 
                                                        # 50 different sizes of the training set
                                                        train_sizes=np.linspace(0.01, 1.0, 50))

plot_learning_curve(train_sizes,train_scores,test_scores, curve_name = 'Logistic regression')

"""2. Maximum iterations tuning"""

#Learn the hyperparameter maximum iterations 
X_train, X_test, y_train, y_test = split_data(outlierless_dt,target='NSP')
param_range = np.arange(0, 300, 10 )

train_scores, test_scores = validation_curve(LogisticRegression(class_weight = 'balanced'), X_train, y_train, param_name = "max_iter",param_range = param_range
                ,scoring = 'accuracy',n_jobs=-1)
plot_validation_curve2(train_scores,test_scores,param_name= 'Maximum iterations')

"""2.1 Learn the hyperparameter regularization constant"""

#Learn the hyperparameter regularization constant 
X_train, X_test, y_train, y_test = split_data(outlierless_dt,target='NSP')

#param_range = np.arange(.1, 2, .1 )
param_range = np.logspace(start=-5, stop= .31, base= 10 )
train_scores, test_scores = validation_curve(LogisticRegression(class_weight = 'balanced'), X_train, y_train, param_name = "C",param_range = param_range
                ,scoring = 'accuracy',n_jobs=-1)
plot_validation_curve2(train_scores,test_scores,param_name= 'Regularization Constant')

#Train the logistic regression model using the tuned hyperparameters
score,cm,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test = custom_logistic_regression(outlierless_dt,'NSP',max_iter=50,class_weight='balanced',C=0.8)

plot_conf_matrix(y_test, y_pred_bin,classes=3)

plot_roc_auc(y_test,y_pred_quant, classno = 0, class_name = 'Normal')



plot_roc_auc(y_test,y_pred_quant, classno = 1, class_name = 'Suspected')

plot_roc_auc(y_test,y_pred_quant, classno = 2, class_name = 'Pathologic')

"""Determine the variable importances for logistic regression"""

#Determine the variable importances for logistic regression

"""**Logistic regression model with selected features**"""

#Make a logistic regression model using mrmr selected features
score,cm,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test = custom_logistic_regression(final_dt,'NSP',max_iter=50,class_weight='balanced',C=0.8)

plot_conf_matrix(y_test, y_pred_bin,classes=3)

plot_roc_auc(y_test,y_pred_quant, classno = 0, class_name = 'Normal')

plot_roc_auc(y_test,y_pred_quant, classno = 1, class_name = 'Suspected')

plot_roc_auc(y_test,y_pred_quant, classno = 2, class_name = 'Pathologic')

"""**3. Random Forest Analysis**

1.   Plot Learning curve
2.   Tune number of trees
3.   Tune maximum depth of trees
4.   Build model
5.   confusion matrix and performance metrics
6.   ROC and AUC
7.   variable importances

1. plot learning curve for random forest
"""

#plotting the learning curve
# Create CV training and test scores for various training set sizes
X_train, X_test, y_train, y_test = split_data(outlierless_dt,target='NSP')
train_sizes, train_scores, test_scores = learning_curve(RandomForestClassifier(class_weight='balanced'), 
                                                        X_train, 
                                                        y_train,
                                                        # Number of folds in cross-validation
                                                        cv=10,
                                                        # Evaluation metric
                                                        scoring='accuracy',
                                                        # Use all computer cores
                                                        n_jobs=-1, 
                                                        # 50 different sizes of the training set
                                                        train_sizes=np.linspace(0.01, 1.0, 50))

plot_learning_curve(train_sizes,train_scores,test_scores, curve_name = 'Random Forest')

"""2. validation curve for number of trees"""

#Learn the hyperparameter maximum iterations 
X_train, X_test, y_train, y_test = split_data(outlierless_dt,target='NSP')
param_range = np.arange(1, 200, 2)

train_scores, test_scores = validation_curve(RandomForestClassifier(class_weight = 'balanced'), X_train, y_train, param_name = "n_estimators",param_range = param_range
                ,scoring = 'accuracy',n_jobs=-1)
plot_validation_curve(train_scores,test_scores,param_name= 'number of trees')

"""3. Tune the parameter max_depth"""

#Learn the hyperparameter max_depth
X_train, X_test, y_train, y_test = split_data(outlierless_dt,target='NSP')
param_range = np.arange(1, 50, 1)

train_scores, test_scores = validation_curve(RandomForestClassifier(class_weight = 'balanced'), X_train, y_train, param_name = "max_depth",param_range = param_range
                ,scoring = 'accuracy',n_jobs=-1)
plot_validation_curve(train_scores,test_scores,param_name= 'Tree depth')

"""4. Build model"""

#Build a random forest model with preprocessed dataset and balanced class weights
score,cm,tree,importances,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test = custom_random_forest(outlierless_dt,'NSP',max_depth=10, n_estimators=500,class_weight='balanced')

plot_conf_matrix(y_test, y_pred_bin,classes=3)

plot_roc_auc(y_test,y_pred_quant, classno = 0, class_name = 'Normal')

plot_roc_auc(y_test,y_pred_quant, classno = 1, class_name = 'Suspected')

plot_roc_auc(y_test,y_pred_quant, classno = 2, class_name = 'Pathologic')

#compute the variable importances
rf_var_importance(importances,X_train)

"""**Build random forest with selected features**"""

#Build a random forest model with preprocessed dataset and balanced class weights
score,cm,tree,importances,y_predict,y_pred_quant,y_pred_bin,X_train, X_test, y_train, y_test = custom_random_forest(final_dt,'NSP',max_depth=10, n_estimators=500,class_weight='balanced')

plot_conf_matrix(y_test, y_pred_bin,classes=3)

plot_roc_auc(y_test,y_pred_quant, classno = 0, class_name = 'Normal')

plot_roc_auc(y_test,y_pred_quant, classno = 1, class_name = 'Suspected')

plot_roc_auc(y_test,y_pred_quant, classno = 2, class_name = 'Pathologic')